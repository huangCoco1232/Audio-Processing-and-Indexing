# gateway/app.py

import os
import time
import json
import requests
import streamlit as st
from io import BytesIO
from audiorecorder import audiorecorder  # streamlit-audiorecorder

# ===== é…ç½® =====
ASR_URL = "http://localhost:8001/asr"
LLM_URL = "http://localhost:8002/llm"
TTS_URL = "http://localhost:8003/tts"

st.set_page_config(page_title="Voice Chat Gateway")
st.title("ğŸ¤ è¯­éŸ³åŠ©æ‰‹ï¼ˆASR â†’ LLM â†’ TTSï¼‰")

OUTPUT_DIR = "output"
os.makedirs(OUTPUT_DIR, exist_ok=True)


def clear_chat_history():
    if "messages" in st.session_state:
        del st.session_state.messages


def init_chat_history():
    if "messages" not in st.session_state:
        st.session_state.messages = []
        with st.chat_message("assistant", avatar='ğŸ¤–'):
            st.markdown("ä½ å¥½ï¼è¯·æŒ‰ä¸‹å½•éŸ³æŒ‰é’®å¼€å§‹è®²è¯ï¼Œæˆ‘ä¼šå¸®ä½ å®Œæˆ ASR â†’ LLM â†’ TTS å…¨æµç¨‹ ğŸ˜Š")

    # é‡æ–°æ¸²æŸ“å†å²å¯¹è¯
    for msg in st.session_state.messages:
        avatar = "ğŸ§‘â€ğŸ’»" if msg["role"] == "user" else "ğŸ¤–"
        with st.chat_message(msg["role"], avatar=avatar):
            st.markdown(msg["content"])

    return st.session_state.messages


def call_asr(audio_bytes):
    """è°ƒç”¨ ASR æœåŠ¡"""
    files = {"file": ("audio.wav", audio_bytes, "audio/wav")}
    resp = requests.post(ASR_URL, files=files)
    return resp.json().get("text", "")


def call_llm(text):
    """è°ƒç”¨ LLM æœåŠ¡"""
    payload = {"text": text}
    resp = requests.post(LLM_URL, json=payload)
    return resp.json().get("reply", "")


def call_tts(text):
    """è°ƒç”¨ TTS æœåŠ¡"""
    data = {"text": text}
    resp = requests.post(TTS_URL, data=data)
    return resp.content  # wav bytes


def main():
    messages = init_chat_history()

    st.markdown("### ğŸ™ï¸ æŒ‰ä¸‹æŒ‰é’®å¼€å§‹å½•éŸ³")
    audio = audiorecorder("å¼€å§‹å½•éŸ³", "æ­£åœ¨å½•éŸ³... ç‚¹å‡»åœæ­¢")

    if len(audio) > 0:
        # audio æ˜¯ä¸€ä¸ª AudioSegment
        buf = BytesIO()
        audio.export(buf, format="wav")
        audio_bytes = buf.getvalue()

        # é¿å…é‡å¤å¤„ç†
        if st.session_state.get("last_audio_len", 0) == len(audio_bytes):
            return
        st.session_state["last_audio_len"] = len(audio_bytes)

        # å‰ç«¯æ’­æ”¾ç”¨æˆ·å½•éŸ³
        st.markdown("#### ğŸ”Š ä½ åˆšåˆšå½•çš„éŸ³é¢‘ï¼š")
        st.audio(audio_bytes, format="audio/wav")

        # ä¿å­˜éŸ³é¢‘æ–‡ä»¶ï¼ˆå¯è°ƒè¯•ï¼‰
        ts = time.strftime("%Y%m%d_%H%M%S")
        save_path = os.path.join(OUTPUT_DIR, f"{ts}.wav")
        with open(save_path, "wb") as f:
            f.write(audio_bytes)

        st.success(f"å½•éŸ³å·²ä¿å­˜åˆ°: `{save_path}`")

        # =============== 1. Whisper ASR ===============
        with st.spinner("æ­£åœ¨è¯†åˆ«è¯­éŸ³ (ASR)..."):
            text = call_asr(audio_bytes)

        if not text:
            st.error("ASR æ²¡è¯†åˆ«åˆ°å†…å®¹ï¼Œè¯·å†è¯•ä¸€æ¬¡ã€‚")
            return

        messages.append({"role": "user", "content": text})
        with st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»"):
            st.markdown(text)

        # =============== 2. LLM èŠå¤© ===============
        with st.spinner("æ­£åœ¨ç”Ÿæˆ LLM å›å¤..."):
            reply = call_llm(text)

        messages.append({"role": "assistant", "content": reply})
        with st.chat_message("assistant", avatar="ğŸ¤–"):
            st.markdown(reply)

        # =============== 3. TTS åˆæˆ ===============
        with st.spinner("æ­£åœ¨è¯­éŸ³åˆæˆ (TTS)..."):
            tts_audio = call_tts(reply)

        st.markdown("#### ğŸ—£ï¸ åˆæˆè¯­éŸ³å›å¤ï¼š")
        st.audio(tts_audio, format="audio/wav")

    st.button("æ¸…ç©ºå¯¹è¯", on_click=clear_chat_history)


if __name__ == "__main__":
    main()